---
title: "p8150_hw2_wz2629"
author: Wen Dai
date: "2023-09-27"
output: 
  github_document
---

```{r message=FALSE}
library (tidyverse)
library(readxl)
```

# Problem 1:
Step1 : clean the data in pols-month.csv
```{r}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

polmonth_df = 
  read_csv("fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez"))
```

Step 2: clean the data in snp.csv

```{r}
snp_df = 
  read_csv(
    "fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```


Step 3: clean the data in unemployment.csv
```{r}
  unemployment_df=read_csv("fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)

```

step 4:
Join the dataset by merging snp into pols, and merging unemployment into the result.
```{r}
combine = 
  left_join(polmonth_df, snp_df) |>
  left_join(x = _, y = unemployment_df)

str(combine)
```

Step 5:
Write a short paragraph about these data set.
Explain briefly what each dataset contained, and describe the resulting dataset. 
(e.g. give the dimension, range of years and names of key variables)

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the "combine_df" datasets. The `polmonth_df` data has `r nrow(polmonth_df)` observations and `r ncol(polmonth_df)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r polmonth_df |> pull(year) |> min()` to `r polmonth_df |> pull(year) |> max()`. It also tells us whether the sitting president was a democrat or republican. 

The `snp_df` data has `r nrow(snp_df)` observations and `r ncol(snp_df)` variables, ranging from years `r snp_df |> pull(year) |> min()` to `r snp_df |> pull(year) |> max()`. 

The `unemployment_df` data has `r nrow(unemployment_df)` observations and `r ncol(unemployment_df)` variables ranging from years `r unemployment_df |> pull(year) |> min()` to `r unemployment_df |> pull(year) |> max()`.

In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(combine, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(combine, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.

# Problem 2:

Step 1: Tidy Mr. trashwheel's dataset
```{r}
Mr_df = read_excel("202309 Trash Wheel Collection Data.xlsx", sheet="Mr. Trash Wheel",skip=1,range="A2:N587") |> 
  janitor::clean_names() |> 
drop_na(dumpster) |> 
  mutate(
 homes_powered=weight_tons*500/30,
TrashWheel="Mr.Trash Wheel")|> 
  mutate (year=as.character(year)) |> 
  select(dumpster, month, year, date, weight=weight_tons,volume=volume_cubic_yards, bottles=plastic_bottles,polystyrene,cigarette=cigarette_butts,glass=glass_bottles,bags=plastic_bags,wrappers,sports=sports_balls,homes_powered,TrashWheel)
```

Step 2: Tidy Professor Trash Wheel
```{r}
Professor_df = read_excel("202309 Trash Wheel Collection Data.xlsx", sheet="Professor Trash Wheel",skip=1,range="A2:M109") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
 homes_powered=weight_tons*500/30,
TrashWheel="Professor Trash Wheel") |> 
  mutate (year=as.character(year)) |> 
  select(dumpster, month, year, date, weight=weight_tons, volume=volume_cubic_yards,bottles=plastic_bottles, polystyrene, cigarette=cigarette_butts,glass=glass_bottles,plastic=plastic_bags,wrappers,homes_powered,TrashWheel)
```

Step 3: Tidy Gwynnda Trash Wheel 
```{r}
Gwynnda_df = read_excel("202309 Trash Wheel Collection Data.xlsx", sheet="Gwynnda Trash Wheel",skip=1, range="A2:L159") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
 homes_powered=weight_tons*500/30,
TrashWheel="Professor Trash Wheel")|> 
  mutate (year=as.character(year)) |> 
  select(dumpster, month, year, date, weight=weight_tons, volume=volume_cubic_yards,bottles=plastic_bottles, polystyrene, cigarette=cigarette_butts,plastic=plastic_bags,wrappers,homes_powered,TrashWheel)
```

Step 4: Combine these dataset with Mr. Trash Wheel datset to produce a single tidy dataset,.

```{r}
TW_df=bind_rows(Mr_df,Professor_df,Gwynnda_df)

July_2021_Gwynnda<-subset(Gwynnda_df,year=="2021" & month=="July")
total_Cigarette_Gwynnda<-sum(pull(July_2021_Gwynnda,cigarette))
```

Step 5: Write a paragaph about this data.

The `Mr_df` data has `r nrow(Mr_df)` observations and `r ncol(Mr_df)` variables. The key variables are include: date, weight_tons, home_powered and Trashwheel.

The `Professor_df` data has `r nrow(Professor_df)` observations and `r ncol(Professor_df)` variables.The key variables are include: date, weight_tons, homes_powered, and TrashWheel.

The `Gwynnda_df` data has `r nrow(Gwynnda_df)` observations and `r ncol(Gwynnda_df)` variables.The key variables are included: date, weight_tons, homee_powered and trashwheel. 

The total weight of trash collected by Professor Trash wheel is `r sum(pull(Professor_df,weight), na.rm = TRUE)` tons.
The total number of cigarette butts collected by Gwynnda in July of 2021 is 16300.

# Problem 3:

Step 1: tidy the baseline data
```{r}
baseline_df=
  read_csv("data_mci/MCI_baseline.csv",na=c('.'),skip=1) |> 
  janitor::clean_names() |> 
  mutate(
    sex=case_match(
      sex,
      1~"male",
      0~"female"),
    apoe4=case_match(
      apoe4,
      1~"APOE4 carrier",
      0~"APOE4 non-carrier"
    )) |> 
  select(id, baseline_age=current_age, onset_age=age_at_onset,everything()) |> 
  filter(baseline_age<onset_age | is.na(onset_age))
```

Step 2:
Discuss important steps in the import process and relevant features of the dataset. 
```{r}
    participants=nrow(baseline_df)
    MCI_df=filter(baseline_df,onset_age !="na") 
        MCI=nrow(MCI_df)
      
      
    average_age=mean(pull(baseline_df,baseline_age))
    
  female=nrow(filter(baseline_df,sex=="female",apoe4=="APOE4 carrier"))
  female_Prop=female/participants
    
  
```

The important steps in the import process is ensure that Sex and APOE4 carrier status are approporiate encoded and remov any participants who do not meet the stated inclusion criteria which is study participants were free of Mild Cognitive Impairment (MCI), also we use reasonable variable names. 
The `baseline_df` data has `r nrow(baseline_df)` observations and `r ncol(baseline_df)` variables.The important key variables are id, baseline_age, onset_age, sex and apoe4.There are `r nrow(baseline_df)` participants recruited, and of these `r nrow(MCI_df)` develop MCI.The average baseline age is `r mean(pull(baseline_df,baseline_age))` years old. The proportion of women in the study are APOE4 carriers are `r female/participants`





